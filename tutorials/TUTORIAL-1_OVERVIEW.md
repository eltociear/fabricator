# Tutorial 1: Understanding the modules

## General

The modules are the main building blocks of the application. This tutorial will explain the basic concepts of the 
modules and how to use them.

## Datasets

Datasets are build upon the `Dataset` class of the huggingface datasets library. They are used to store the data in a 
tabular format and provide a convenient way to access the data. The generated datasets will always be in that format such
that they can be easily integrated with standard machine learning frameworks or shared with the research community via 
the huggingface hub.

```python
from datasets import load_dataset

# Load the imdb dataset from the huggingface hub, i.e. for annotation
dataset = load_dataset("imdb")

# Load custom dataset from a jsonl file
dataset = load_dataset("json", data_files="path/to/file.jsonl")

# Share generated dataset with the huggingface hub
dataset.push_to_hub("my-dataset")
```

## LLMs
We use haystack's `PromptNode` to generate the data. The PromptNode is a wrapper for multiple LLMs such as the ones
from OpenAI or all available models on the huggingface hub. You can set all generation-related parameters such as 
temperature, top_k, maximum generation length via the PromptNode.

```python
import os
from haystack.nodes import PromptNode

# Load a model from huggingface hub
prompt_node = PromptNode("google/flan-t5-base")

# Create a PromptNode with the OpenAI API
prompt_node = PromptNode(
    model_name_or_path="text-davinci-003",
    api_key=os.environ.get("OPENAI_API_KEY"),
)
```

## Prompt Templates

Prompt templates are used to generate the prompts for the LLMs. This class is highly flexible and is used to define (i)
the task description (what should the LLM generate), (ii) label options to choose from when i.e. classiyfing text and 
(iii) the format of optional fewshot examples. The prompt template instance will be passed to the `DatasetGenerator` 
class and, if fewshot examples are passed, create the final prompts based on the columns present in the dataset.

<ins>Note:</ins> Since the `DatasetGenerator` class parses the generated output directly into the target dataset format: Ensure that
your prompt generates exactly one data point per prompt since the output will be taken as is.

### Create a minimal prompt for generating text without fewshot examples

```python
from ai_dataset_generator.prompts import BasePrompt

prompt_template = BasePrompt(task_description="Generate movie reviews.")
print(prompt_template.get_prompt_text())
```
Output:
```console
Generate movies reviews.

text: 
```

### Create a prompt with label options
Label options are insert into a formattable task description to guide the LLM to generate the desired output. The label 
options are a list of strings. When generating data, the `DatasetGenerator` class will uniformly sample
one of the label options and insert it into the task description such that the generated dataset is balanced.

```python
from ai_dataset_generator.prompts import BasePrompt

label_options = ["positive", "negative"]
prompt_template = BasePrompt(
    task_description="Generate a {} movie review.",
    label_options=label_options,
)

for label in label_options:
    print(prompt_template.get_prompt_text(label) + "\n---\n")
```
Output:
```console
Generate a positive movie reviews.

text:
---

Generate a negative movie reviews.

text: 
---
```

### Create a prompt that generates movie reviews with fewshot examples

With fewshot examples, we are able to create a additional training examples for a tiny dataset. The 
`generate_data_for_column` variable defines the column that should be generated by the LLM and can be any column from 
the dataset. As previously introduced, the `DatasetGenerator` will create a balanced dataset by uniformly sampling from 
the label options. At runtime, when generating additional data, the `DatasetGenerator` samples data points from the 
fewshot dataset that have the same label as used in the task description as exemplarily shown in the output.

```python
from datasets import Dataset
from ai_dataset_generator.prompts import BasePrompt

label_options = ["positive", "negative"]

fewshot_examples = Dataset.from_dict({
    "text": ["This movie is great!", "This movie is bad!"],
    "label": label_options
})

prompt_template = BasePrompt(
    task_description="Generate a {} movie review.",
    label_options=label_options,
    generate_data_for_column="text",
)

for idx, label in enumerate(label_options):
    print(prompt_template.get_prompt_text(label, fewshot_examples.select([idx])) + "\n---\n")
```

Output:
```console
Generate a positive movie review.

text: This movie is great!

text: 
---

Generate a negative movie review.

text: This movie is bad!

text: 
---
```

### Create a prompt that annotates unlabeled movie reviews with fewshot examples
If you want to annotate unlabeled data, you can use the `fewshot_example_columns` attribute to define the columns that
should be used as fewshot examples. The `generate_data_for_column` variable now defines the column that should be 
annotated by the LLM as illustrated in the previous example.

```python
from datasets import Dataset
from ai_dataset_generator.prompts import BasePrompt

label_options = ["positive", "negative"]

fewshot_examples = Dataset.from_dict({
    "text": ["This movie is great!", "This movie is bad!"],
    "label": label_options
})

prompt_template = BasePrompt(
    task_description="Annotate movie reviews as either: {}.",
    label_options=["positive", "negative"],
    generate_data_for_column="label",
    fewshot_example_columns="text",
)

print(prompt_template.get_prompt_text(label_options, fewshot_examples) + "\n---")

invocation_context = {"text": "This movie was a blast!"}
print(prompt_template.get_prompt_text(label_options, fewshot_examples).format(**invocation_context))
```

Output:
```console
Annotate movie reviews as either: positive, negative.

text: This movie is great!
label: positive

text: This movie is bad!
label: negative

text: {text}
label: 
---
Annotate movie reviews as either: positive, negative.

text: This movie is great!
label: positive

text: This movie is bad!
label: negative

text: This movie was a blast!
label: 
```

## DatasetGenerator

The `DatasetGenerator` class is used to generate the final dataset. It takes a `Dataset`, a `PromptNode` and a 
`BasePrompt` as inputs and generates the final dataset based on the prompt template and the optionally provided
fewshot examples. The `generate` method returns a `Dataset` object that can be used with standard machine learning
frameworks such as `transformers`.

```python
from datasets import Dataset
from ai_dataset_generator import DatasetGenerator

fewshot_examples = Dataset.from_dict({
    "text": ["This movie is great!", "This movie is bad!"],
    "label": ["positive", "negative"]
})

unlabeled_dataset = Dataset.from_dict({
    "text": ["This movie was okay!", "This movie is better than I expected!"],
})

generator = DatasetGenerator(prompt_node)
generated_dataset = generator.generate(
    fewshot_dataset=fewshot_examples,
    unlabeled_dataset=unlabeled_dataset,
    prompt_template=prompt_template,  # from above
    max_prompt_calls=5,  # max number of calls to the LLM
    fewshot_examples_per_class=1,  # number of fewshot examples per class per prompt
)
```
